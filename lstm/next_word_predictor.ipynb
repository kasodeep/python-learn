{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3958,"status":"ok","timestamp":1701367332574,"user":{"displayName":"Anish Deshpande","userId":"03261754914657935234"},"user_tz":-330},"id":"19US0TCXtjJc","outputId":"5bad0fb8-67d9-46b3-8ad9-75cdd0da4846"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["# Importing the dataset.\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":420,"status":"ok","timestamp":1701367335153,"user":{"displayName":"Anish Deshpande","userId":"03261754914657935234"},"user_tz":-330},"id":"lhD8hysKAGkI"},"outputs":[],"source":["# Opening the text file for dataset.\n","f = open('/content/drive/MyDrive/Baskerville.txt', 'r')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":439,"status":"ok","timestamp":1701367338280,"user":{"displayName":"Anish Deshpande","userId":"03261754914657935234"},"user_tz":-330},"id":"SRSMSIZlvYoL"},"outputs":[],"source":["# Few Imports\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.text import Tokenizer"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":440,"status":"ok","timestamp":1701367340790,"user":{"displayName":"Anish Deshpande","userId":"03261754914657935234"},"user_tz":-330},"id":"DvSUw-qP8AKx"},"outputs":[],"source":["tokenizer = Tokenizer()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1217,"status":"ok","timestamp":1701367343879,"user":{"displayName":"Anish Deshpande","userId":"03261754914657935234"},"user_tz":-330},"id":"i8KPhN0ZAkBw"},"outputs":[],"source":["# Reading the dataset.\n","text = f.read()\n","text.strip\n","f.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":467,"status":"ok","timestamp":1701367346419,"user":{"displayName":"Anish Deshpande","userId":"03261754914657935234"},"user_tz":-330},"id":"NaTqiH1v8DT8"},"outputs":[],"source":["# Vectorizing the data.\n","tokenizer.fit_on_texts([text])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":520,"status":"ok","timestamp":1701367348932,"user":{"displayName":"Anish Deshpande","userId":"03261754914657935234"},"user_tz":-330},"id":"Yu7Edxcs8LFl","outputId":"516a5662-b73e-49e2-a50b-574fa0be1a0a"},"outputs":[{"name":"stdout","output_type":"stream","text":["3680\n"]}],"source":["tokenizer.word_index\n","words = len(tokenizer.word_index)\n","print(words)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":406,"status":"ok","timestamp":1701367352042,"user":{"displayName":"Anish Deshpande","userId":"03261754914657935234"},"user_tz":-330},"id":"3R6efnv8OadX"},"outputs":[],"source":["# Creating the dataset.\n","input_sequences = []\n","for sentence in text.split('\\n'):\n","  tokenized_sentence = tokenizer.texts_to_sequences([sentence])[0]\n","\n","  for i in range(1, len(tokenized_sentence)):\n","    input_sequences.append(tokenized_sentence[:i+1])\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":423,"status":"ok","timestamp":1701367358111,"user":{"displayName":"Anish Deshpande","userId":"03261754914657935234"},"user_tz":-330},"id":"nYdr_626eg2P","outputId":"bc6c03bb-719e-4284-e978-c9be2f017e9b"},"outputs":[{"name":"stdout","output_type":"stream","text":["18\n"]}],"source":["max_length = max(len(x) for x in input_sequences)\n","print(max_length)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":433,"status":"ok","timestamp":1701367360484,"user":{"displayName":"Anish Deshpande","userId":"03261754914657935234"},"user_tz":-330},"id":"ySyRBOOk4Hz-"},"outputs":[],"source":["# Same size sequences.\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","padded_input_sequences = pad_sequences(input_sequences, maxlen = max_length, padding = 'pre')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":423,"status":"ok","timestamp":1701367363830,"user":{"displayName":"Anish Deshpande","userId":"03261754914657935234"},"user_tz":-330},"id":"ATEa-o7S-b6A"},"outputs":[],"source":["X = padded_input_sequences[:,:-1]"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1701367365822,"user":{"displayName":"Anish Deshpande","userId":"03261754914657935234"},"user_tz":-330},"id":"VrK-uSKiCE5T"},"outputs":[],"source":["y = padded_input_sequences[:,-1]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":800,"status":"ok","timestamp":1701367369410,"user":{"displayName":"Anish Deshpande","userId":"03261754914657935234"},"user_tz":-330},"id":"0pl0ihj7cjv6","outputId":"90e9fedb-f3f2-41c1-efdf-b310fb7ce227"},"outputs":[{"data":{"text/plain":["(21733, 17)"]},"execution_count":38,"metadata":{},"output_type":"execute_result"}],"source":["X.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":648,"status":"ok","timestamp":1701367374913,"user":{"displayName":"Anish Deshpande","userId":"03261754914657935234"},"user_tz":-330},"id":"sO7UU2X1csPI","outputId":"6316f968-85f2-45d3-fe07-0a6d7abc018d"},"outputs":[{"data":{"text/plain":["(21733,)"]},"execution_count":39,"metadata":{},"output_type":"execute_result"}],"source":["y.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1701367377238,"user":{"displayName":"Anish Deshpande","userId":"03261754914657935234"},"user_tz":-330},"id":"NaIuabjlCYvp"},"outputs":[],"source":["# Adding number of words.\n","from tensorflow.keras.utils import to_categorical\n","y = to_categorical(y, num_classes = words + 1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":434,"status":"ok","timestamp":1701367379898,"user":{"displayName":"Anish Deshpande","userId":"03261754914657935234"},"user_tz":-330},"id":"YWCvi4jncvqF","outputId":"2d408764-adce-4401-e465-3f0e1c6bf460"},"outputs":[{"data":{"text/plain":["(21733, 3681)"]},"execution_count":41,"metadata":{},"output_type":"execute_result"}],"source":["y.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":431,"status":"ok","timestamp":1701367388522,"user":{"displayName":"Anish Deshpande","userId":"03261754914657935234"},"user_tz":-330},"id":"Pr4fEuE9N0Mw"},"outputs":[],"source":["# Importing the models.\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, LSTM, Dense\n","import numpy as np"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":439,"status":"ok","timestamp":1701367393113,"user":{"displayName":"Anish Deshpande","userId":"03261754914657935234"},"user_tz":-330},"id":"rsX5VLBvVz5G"},"outputs":[],"source":["# Initializing the model.\n","model = Sequential()\n","model.add(Embedding(words + 1, 100, input_length = 17))\n","model.add(LSTM(150))\n","model.add(Dense(words + 1, activation = 'softmax'))"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":468,"status":"ok","timestamp":1701367396052,"user":{"displayName":"Anish Deshpande","userId":"03261754914657935234"},"user_tz":-330},"id":"myAZl2X6WPSS"},"outputs":[],"source":["# Compiling the model.\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1701367398027,"user":{"displayName":"Anish Deshpande","userId":"03261754914657935234"},"user_tz":-330},"id":"47oGV0cbkNIa","outputId":"94090c3f-4f46-4e1e-c2b6-835062c04de9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_2 (Embedding)     (None, 17, 100)           368100    \n","                                                                 \n"," lstm_2 (LSTM)               (None, 150)               150600    \n","                                                                 \n"," dense_2 (Dense)             (None, 3681)              555831    \n","                                                                 \n","=================================================================\n","Total params: 1074531 (4.10 MB)\n","Trainable params: 1074531 (4.10 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}],"source":["# Summarizing the model.\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1513540,"status":"ok","timestamp":1701370849119,"user":{"displayName":"Anish Deshpande","userId":"03261754914657935234"},"user_tz":-330},"id":"YBwt_ZBjbGBj","outputId":"16a6f96e-34a1-478a-e0f3-67fffde2a5da"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/100\n","680/680 [==============================] - 37s 50ms/step - loss: 6.4398 - accuracy: 0.0583\n","Epoch 2/100\n","680/680 [==============================] - 34s 50ms/step - loss: 5.9618 - accuracy: 0.0723\n","Epoch 3/100\n","680/680 [==============================] - 34s 50ms/step - loss: 5.6409 - accuracy: 0.0936\n","Epoch 4/100\n","680/680 [==============================] - 34s 49ms/step - loss: 5.3164 - accuracy: 0.1152\n","Epoch 5/100\n","680/680 [==============================] - 34s 50ms/step - loss: 5.0462 - accuracy: 0.1312\n","Epoch 6/100\n","680/680 [==============================] - 34s 50ms/step - loss: 4.7924 - accuracy: 0.1489\n","Epoch 7/100\n","680/680 [==============================] - 35s 51ms/step - loss: 4.5430 - accuracy: 0.1643\n","Epoch 8/100\n","680/680 [==============================] - 34s 50ms/step - loss: 4.3008 - accuracy: 0.1812\n","Epoch 9/100\n","680/680 [==============================] - 34s 50ms/step - loss: 4.0603 - accuracy: 0.1986\n","Epoch 10/100\n","680/680 [==============================] - 34s 51ms/step - loss: 3.8262 - accuracy: 0.2257\n","Epoch 11/100\n","680/680 [==============================] - 34s 50ms/step - loss: 3.5951 - accuracy: 0.2485\n","Epoch 12/100\n","680/680 [==============================] - 34s 50ms/step - loss: 3.3716 - accuracy: 0.2823\n","Epoch 13/100\n","680/680 [==============================] - 34s 50ms/step - loss: 3.1512 - accuracy: 0.3212\n","Epoch 14/100\n","680/680 [==============================] - 35s 51ms/step - loss: 2.9396 - accuracy: 0.3578\n","Epoch 15/100\n","680/680 [==============================] - 34s 50ms/step - loss: 2.7389 - accuracy: 0.3997\n","Epoch 16/100\n","680/680 [==============================] - 34s 51ms/step - loss: 2.5499 - accuracy: 0.4356\n","Epoch 17/100\n","680/680 [==============================] - 34s 50ms/step - loss: 2.3733 - accuracy: 0.4758\n","Epoch 18/100\n","680/680 [==============================] - 34s 51ms/step - loss: 2.2076 - accuracy: 0.5125\n","Epoch 19/100\n","680/680 [==============================] - 34s 50ms/step - loss: 2.0514 - accuracy: 0.5454\n","Epoch 20/100\n","680/680 [==============================] - 34s 51ms/step - loss: 1.9071 - accuracy: 0.5766\n","Epoch 21/100\n","680/680 [==============================] - 34s 51ms/step - loss: 1.7723 - accuracy: 0.6084\n","Epoch 22/100\n","680/680 [==============================] - 34s 51ms/step - loss: 1.6444 - accuracy: 0.6406\n","Epoch 23/100\n","680/680 [==============================] - 35s 51ms/step - loss: 1.5262 - accuracy: 0.6670\n","Epoch 24/100\n","680/680 [==============================] - 34s 50ms/step - loss: 1.4145 - accuracy: 0.6924\n","Epoch 25/100\n","680/680 [==============================] - 34s 50ms/step - loss: 1.3123 - accuracy: 0.7171\n","Epoch 26/100\n","680/680 [==============================] - 34s 51ms/step - loss: 1.2166 - accuracy: 0.7410\n","Epoch 27/100\n","680/680 [==============================] - 34s 51ms/step - loss: 1.1249 - accuracy: 0.7622\n","Epoch 28/100\n","680/680 [==============================] - 35s 51ms/step - loss: 1.0417 - accuracy: 0.7816\n","Epoch 29/100\n","680/680 [==============================] - 34s 50ms/step - loss: 0.9639 - accuracy: 0.8005\n","Epoch 30/100\n","680/680 [==============================] - 34s 50ms/step - loss: 0.8919 - accuracy: 0.8155\n","Epoch 31/100\n","680/680 [==============================] - 34s 50ms/step - loss: 0.8273 - accuracy: 0.8311\n","Epoch 32/100\n","680/680 [==============================] - 34s 50ms/step - loss: 0.7652 - accuracy: 0.8447\n","Epoch 33/100\n","680/680 [==============================] - 34s 51ms/step - loss: 0.7108 - accuracy: 0.8552\n","Epoch 34/100\n","680/680 [==============================] - 34s 51ms/step - loss: 0.6631 - accuracy: 0.8673\n","Epoch 35/100\n","680/680 [==============================] - 34s 51ms/step - loss: 0.6144 - accuracy: 0.8782\n","Epoch 36/100\n","680/680 [==============================] - 34s 50ms/step - loss: 0.5704 - accuracy: 0.8863\n","Epoch 37/100\n","680/680 [==============================] - 34s 51ms/step - loss: 0.5314 - accuracy: 0.8932\n","Epoch 38/100\n","680/680 [==============================] - 35s 51ms/step - loss: 0.5003 - accuracy: 0.8984\n","Epoch 39/100\n","680/680 [==============================] - 34s 50ms/step - loss: 0.4687 - accuracy: 0.9046\n","Epoch 40/100\n","680/680 [==============================] - 35s 51ms/step - loss: 0.4410 - accuracy: 0.9079\n","Epoch 41/100\n","680/680 [==============================] - 33s 49ms/step - loss: 0.4175 - accuracy: 0.9122\n","Epoch 42/100\n","680/680 [==============================] - 34s 51ms/step - loss: 0.3959 - accuracy: 0.9137\n","Epoch 43/100\n","680/680 [==============================] - 34s 50ms/step - loss: 0.3770 - accuracy: 0.9163\n","Epoch 44/100\n","680/680 [==============================] - 34s 50ms/step - loss: 0.3597 - accuracy: 0.9196\n","Epoch 45/100\n","680/680 [==============================] - 35s 51ms/step - loss: 0.3426 - accuracy: 0.9218\n","Epoch 46/100\n","680/680 [==============================] - 35s 51ms/step - loss: 0.3290 - accuracy: 0.9219\n","Epoch 47/100\n","680/680 [==============================] - 34s 50ms/step - loss: 0.3185 - accuracy: 0.9231\n","Epoch 48/100\n","680/680 [==============================] - 33s 49ms/step - loss: 0.3084 - accuracy: 0.9245\n","Epoch 49/100\n","680/680 [==============================] - 33s 49ms/step - loss: 0.2957 - accuracy: 0.9253\n","Epoch 50/100\n","680/680 [==============================] - 34s 50ms/step - loss: 0.2896 - accuracy: 0.9261\n","Epoch 51/100\n","680/680 [==============================] - 33s 49ms/step - loss: 0.2824 - accuracy: 0.9260\n","Epoch 52/100\n","680/680 [==============================] - 33s 49ms/step - loss: 0.2761 - accuracy: 0.9267\n","Epoch 53/100\n","680/680 [==============================] - 34s 51ms/step - loss: 0.2677 - accuracy: 0.9264\n","Epoch 54/100\n","680/680 [==============================] - 35s 51ms/step - loss: 0.2675 - accuracy: 0.9263\n","Epoch 55/100\n","680/680 [==============================] - 33s 49ms/step - loss: 0.2638 - accuracy: 0.9264\n","Epoch 56/100\n","680/680 [==============================] - 32s 48ms/step - loss: 0.2568 - accuracy: 0.9270\n","Epoch 57/100\n","680/680 [==============================] - 33s 49ms/step - loss: 0.2517 - accuracy: 0.9268\n","Epoch 58/100\n","680/680 [==============================] - 34s 49ms/step - loss: 0.2476 - accuracy: 0.9269\n","Epoch 59/100\n","680/680 [==============================] - 33s 49ms/step - loss: 0.2448 - accuracy: 0.9284\n","Epoch 60/100\n","680/680 [==============================] - 33s 49ms/step - loss: 0.2456 - accuracy: 0.9277\n","Epoch 61/100\n","680/680 [==============================] - 34s 50ms/step - loss: 0.2430 - accuracy: 0.9256\n","Epoch 62/100\n","680/680 [==============================] - 35s 51ms/step - loss: 0.2401 - accuracy: 0.9271\n","Epoch 63/100\n","680/680 [==============================] - 34s 49ms/step - loss: 0.2353 - accuracy: 0.9272\n","Epoch 64/100\n","680/680 [==============================] - 33s 49ms/step - loss: 0.2332 - accuracy: 0.9271\n","Epoch 65/100\n","680/680 [==============================] - 33s 49ms/step - loss: 0.2318 - accuracy: 0.9278\n","Epoch 66/100\n","680/680 [==============================] - 33s 49ms/step - loss: 0.2322 - accuracy: 0.9273\n","Epoch 67/100\n","680/680 [==============================] - 33s 49ms/step - loss: 0.2296 - accuracy: 0.9274\n","Epoch 68/100\n","680/680 [==============================] - 34s 49ms/step - loss: 0.2275 - accuracy: 0.9273\n","Epoch 69/100\n","680/680 [==============================] - 34s 49ms/step - loss: 0.2273 - accuracy: 0.9264\n","Epoch 70/100\n","680/680 [==============================] - 34s 50ms/step - loss: 0.2238 - accuracy: 0.9270\n","Epoch 71/100\n","680/680 [==============================] - 35s 51ms/step - loss: 0.2259 - accuracy: 0.9274\n","Epoch 72/100\n","680/680 [==============================] - 34s 50ms/step - loss: 0.2401 - accuracy: 0.9240\n","Epoch 73/100\n","680/680 [==============================] - 33s 49ms/step - loss: 0.2252 - accuracy: 0.9267\n","Epoch 74/100\n","680/680 [==============================] - 33s 49ms/step - loss: 0.2175 - accuracy: 0.9267\n","Epoch 75/100\n","680/680 [==============================] - 33s 49ms/step - loss: 0.2172 - accuracy: 0.9269\n","Epoch 76/100\n","680/680 [==============================] - 33s 49ms/step - loss: 0.2172 - accuracy: 0.9279\n","Epoch 77/100\n","680/680 [==============================] - 34s 49ms/step - loss: 0.2183 - accuracy: 0.9275\n","Epoch 78/100\n","680/680 [==============================] - 36s 52ms/step - loss: 0.2179 - accuracy: 0.9276\n","Epoch 79/100\n","680/680 [==============================] - 34s 50ms/step - loss: 0.2190 - accuracy: 0.9274\n","Epoch 80/100\n","680/680 [==============================] - 33s 49ms/step - loss: 0.2326 - accuracy: 0.9254\n","Epoch 81/100\n","680/680 [==============================] - 33s 49ms/step - loss: 0.2206 - accuracy: 0.9278\n","Epoch 82/100\n","680/680 [==============================] - 33s 49ms/step - loss: 0.2132 - accuracy: 0.9267\n","Epoch 83/100\n","680/680 [==============================] - 33s 49ms/step - loss: 0.2116 - accuracy: 0.9272\n","Epoch 84/100\n","680/680 [==============================] - 33s 49ms/step - loss: 0.2115 - accuracy: 0.9275\n","Epoch 85/100\n","680/680 [==============================] - 34s 50ms/step - loss: 0.2115 - accuracy: 0.9283\n","Epoch 86/100\n","680/680 [==============================] - 35s 51ms/step - loss: 0.2127 - accuracy: 0.9266\n","Epoch 87/100\n","680/680 [==============================] - 34s 51ms/step - loss: 0.2129 - accuracy: 0.9264\n","Epoch 88/100\n","680/680 [==============================] - 34s 50ms/step - loss: 0.2117 - accuracy: 0.9285\n","Epoch 89/100\n","680/680 [==============================] - 34s 49ms/step - loss: 0.2257 - accuracy: 0.9250\n","Epoch 90/100\n","680/680 [==============================] - 33s 49ms/step - loss: 0.2181 - accuracy: 0.9267\n","Epoch 91/100\n","680/680 [==============================] - 33s 49ms/step - loss: 0.2098 - accuracy: 0.9274\n","Epoch 92/100\n","680/680 [==============================] - 34s 50ms/step - loss: 0.2078 - accuracy: 0.9267\n","Epoch 93/100\n","680/680 [==============================] - 34s 51ms/step - loss: 0.2068 - accuracy: 0.9273\n","Epoch 94/100\n","680/680 [==============================] - 35s 51ms/step - loss: 0.2079 - accuracy: 0.9282\n","Epoch 95/100\n","680/680 [==============================] - 34s 50ms/step - loss: 0.2074 - accuracy: 0.9270\n","Epoch 96/100\n","680/680 [==============================] - 34s 49ms/step - loss: 0.2231 - accuracy: 0.9243\n","Epoch 97/100\n","680/680 [==============================] - 34s 49ms/step - loss: 0.2319 - accuracy: 0.9230\n","Epoch 98/100\n","680/680 [==============================] - 33s 49ms/step - loss: 0.2089 - accuracy: 0.9285\n","Epoch 99/100\n","680/680 [==============================] - 34s 50ms/step - loss: 0.2036 - accuracy: 0.9279\n","Epoch 100/100\n","680/680 [==============================] - 33s 49ms/step - loss: 0.2041 - accuracy: 0.9274\n"]},{"data":{"text/plain":["<keras.src.callbacks.History at 0x793dd65eb4f0>"]},"execution_count":46,"metadata":{},"output_type":"execute_result"}],"source":["# Training the model.\n","model.fit(X,y,epochs=100)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21042,"status":"ok","timestamp":1701370994947,"user":{"displayName":"Anish Deshpande","userId":"03261754914657935234"},"user_tz":-330},"id":"1RxnozXWDJgy","outputId":"86d65caa-c813-4840-b158-0d54b2c481e6"},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 26ms/step\n","Watson and\n","1/1 [==============================] - 0s 33ms/step\n","Watson and yet\n","1/1 [==============================] - 0s 37ms/step\n","Watson and yet at\n","1/1 [==============================] - 0s 22ms/step\n","Watson and yet at the\n","1/1 [==============================] - 0s 22ms/step\n","Watson and yet at the end\n","1/1 [==============================] - 0s 24ms/step\n","Watson and yet at the end of\n","1/1 [==============================] - 0s 24ms/step\n","Watson and yet at the end of three\n","1/1 [==============================] - 0s 22ms/step\n","Watson and yet at the end of three months\n","1/1 [==============================] - 0s 37ms/step\n","Watson and yet at the end of three months i\n","1/1 [==============================] - 0s 35ms/step\n","Watson and yet at the end of three months i was\n"]}],"source":["import time\n","text = \"Watson\"\n","\n","for i in range(10):\n","  # Tokenize.\n","  token_text = tokenizer.texts_to_sequences([text])[0]\n","  # Padding.\n","  padded_token_text = pad_sequences([token_text], maxlen=max_length - 1, padding='pre')\n","  # Predict.\n","  pos = np.argmax(model.predict(padded_token_text))\n","\n","  for word, index in tokenizer.word_index.items():\n","    if index == pos:\n","      text = text + \" \" + word\n","      print(text)\n","      time.sleep(2)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPZ5aKxE7udeFM3y+h1tKtu","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
